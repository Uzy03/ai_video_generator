# app/quick_demo.py

import os, sys
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆapp/quick_demo.pyï¼‰ã®ï¼‘ã¤ä¸Šã€ã¤ã¾ã‚Šãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import numpy as np, cv2
from processing.pipeline import process_frame  # æ—¢å­˜ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–¢æ•°

class Transformer(VideoTransformerBase):
    def transform(self, frame):
        # 1) VideoFrame â†’ NumPy
        img = frame.to_ndarray(format="bgr24")
        # 2) JPEG ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ãƒã‚¤ãƒˆåˆ—å–å¾—
        _, buf = cv2.imencode('.jpg', img)
        # 3) æ—¢å­˜é–¢æ•°ã‚’å‘¼ã³å‡ºã—ï¼ˆbytes â†’ bytesï¼‰
        out_bytes = process_frame(buf.tobytes())
        # 4) JPEG bytes â†’ NumPy
        arr = cv2.imdecode(np.frombuffer(out_bytes, np.uint8), cv2.IMREAD_COLOR)
        # 5) NumPy â†’ VideoFrame ã«æˆ»ã—ã¦è¿”å´
        return frame.from_ndarray(arr, format="bgr24")

st.title("ğŸ¬ AI Video Generator â€” Real-Time Demo")
webrtc_streamer(
    key="video",
    mode="SENDRECV",
    video_transformer_factory=Transformer,
    media_stream_constraints={"video": True, "audio": False},
)
